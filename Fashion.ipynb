{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.FashionMNIST, Statistics\n",
    "using Flux: onehotbatch, onecold, crossentropy, throttle\n",
    "using Base.Iterators: repeated, partition\n",
    "using Printf, BSON, LinearAlgebra\n",
    "train_labels = FashionMNIST.labels();\n",
    "train_imgs = FashionMNIST.images();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10;\n",
    "batch_size = 128;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_minibatch(X, Y, idxs)\n",
    "    X_batch = Array{Float32}(undef, size(X[1])..., 1, length(idxs))\n",
    "    for i in 1:length(idxs)\n",
    "        X_batch[:, :, :, i] = Float32.(X[idxs[i]])\n",
    "    end\n",
    "    Y_batch = onehotbatch(Y[idxs], 0:9)\n",
    "    return (X_batch, Y_batch)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_idxs = partition(1:length(train_imgs), batch_size)\n",
    "train_set = [make_minibatch(train_imgs, train_labels, i) for i in mb_idxs];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test set as one giant minibatch:\n",
    "test_imgs = FashionMNIST.images(:test)\n",
    "test_labels = FashionMNIST.labels(:test)\n",
    "test_set = make_minibatch(test_imgs, test_labels, 1:length(test_imgs));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>64, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 64=>128, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 128=>128, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1=>16, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 16=>32, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>64, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 64=>128, pad=(1,1), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(128, 10),\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nowa prÃ³ba\n",
    "model = Chain(\n",
    "    Conv((5, 5), 1=>32, pad=(2,2), relu),\n",
    "    MaxPool((2,2)),\n",
    "    Conv((3, 3), 32=>64, pad=(2,2), relu),\n",
    "    MaxPool((2,2)),\n",
    "    x -> reshape(x, :, size(x, 4)),\n",
    "    Dense(4096, 10),\n",
    "    softmax,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Conv((5, 5), 1=>32, relu), BatchNorm(32), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), Conv((3, 3), 32=>64, relu), BatchNorm(64), MaxPool((2, 2), pad = (0, 0, 0, 0), stride = (2, 2)), #9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = Chain(model.layers[1:7]...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(train_set[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(x, y)\n",
    "    x_aug = x .+ 0.1f0*randn(eltype(x), size(x))\n",
    "    y_hat = model(x_aug)\n",
    "    return crossentropy(y_hat, y)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2995205f0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(train_set[1][1],train_set[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(x, y) = mean(onecold(model(x)) .== onecold(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0546875"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(train_set[1][1],train_set[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: ADAM not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: ADAM not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[1]:1"
     ]
    }
   ],
   "source": [
    "opt = ADAM(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "InterruptException",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      " [1] try_yieldto(::typeof(Base.ensure_rescheduled), ::Base.RefValue{Task}) at .\\task.jl:517",
      " [2] wait() at .\\task.jl:592",
      " [3] yield at .\\task.jl:479 [inlined]",
      " [4] oslibuv_flush() at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\stdio.jl:267",
      " [5] flush(::IJulia.IJuliaStdio{Base.PipeEndpoint}) at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\stdio.jl:274",
      " [6] flush_all() at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\stdio.jl:257",
      " [7] execute_request(::ZMQ.Socket, ::IJulia.Msg) at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\execute_request.jl:105",
      " [8] #invokelatest#1 at .\\essentials.jl:790 [inlined]",
      " [9] invokelatest at .\\essentials.jl:789 [inlined]",
      " [10] eventloop(::ZMQ.Socket) at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\eventloop.jl:8",
      " [11] eventloop(::ZMQ.Socket) at C:\\Users\\asia0\\.julia\\packages\\IJulia\\DrVMH\\src\\eventloop.jl:28 (repeats 4 times)",
      " [12] (::getfield(IJulia, Symbol(\"##15#18\")))() at .\\task.jl:268"
     ]
    }
   ],
   "source": [
    "Flux.train!(loss, params(model), train_set, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "BSON.@load \"fashionMNIST_conv3.bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@info(\"Beginning training loop...\")\n",
    "best_acc = 0.0\n",
    "last_improvement = 0\n",
    "for epoch = 1:epochs\n",
    "    global best_acc, last_improvement\n",
    "    Flux.train!(loss, params(model), train_set, opt)\n",
    "    acc = accuracy(test_set[1],test_set[2])\n",
    "    @info(@sprintf(\"[%d]: Test accuracy: %.4f\", epoch, acc))\n",
    "    if acc >= 0.91\n",
    "        @info(\" -> Early-exiting: We reached our target accuracy of 91%\")\n",
    "        break\n",
    "    end\n",
    "    if acc >= best_acc\n",
    "        @info(\" -> New best accuracy! Saving model out to fashionMNIST_conv.bson\")\n",
    "        BSON.@save \"fashionMNIST_conv3.bson\" model epoch acc\n",
    "        best_acc = acc\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 5 && opt.eta > 1e-6\n",
    "        opt.eta /= 10.0\n",
    "        @warn(\" -> Haven't improved in a while, dropping learning rate to $(opt.eta)!\")\n",
    "        last_improvement = epoch\n",
    "    end\n",
    "    if epoch - last_improvement >= 10\n",
    "        @warn(\" -> We're calling this converged.\")\n",
    "        break\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
